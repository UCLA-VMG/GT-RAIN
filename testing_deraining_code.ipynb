{"cells":[{"cell_type":"markdown","metadata":{"id":"NzoyVDRdDsoR"},"source":["# Library\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pmJfGpNjOIGn"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","import torchvision.transforms.functional as TF\n","import torchvision\n","import torchvision.utils as vutils\n","\n","from torch.nn import init\n","import functools\n","from PIL import Image\n","import random\n","import os\n","import time\n","import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.axes_grid1 import ImageGrid\n","from pathlib import Path\n","from natsort import natsorted\n","from glob import glob\n","\n","from collections import OrderedDict\n","\n","from tqdm.notebook import tqdm\n","import math\n","\n","from skimage.metrics import peak_signal_noise_ratio as psnr\n","from skimage.metrics import structural_similarity as ssim \n","import pandas as pd\n","import numpy as np\n","import os\n","from os.path import exists\n","from pathlib import Path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QSMchleKO8Zc"},"outputs":[],"source":["# Plot image\n","def show_img(img, title='No Title', normalize_range=False, figsize=15):\n","  plt.figure(figsize=(figsize, figsize))\n","  plt.imshow(img)\n","  plt.title(title)\n","  plt.show()"]},{"cell_type":"markdown","metadata":{"id":"XwbVoPMkCUKr"},"source":["# Model Definitions"]},{"cell_type":"code","source":["# Main network blocks\n","# Code modified from: https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix\n","\n","# Basic Blocks\n","class Identity(nn.Module):\n","  def forward(self, x):\n","    return x\n","\n","def get_norm_layer(norm_type='instance'):\n","  \"\"\"Return a normalization layer\n","  Parameters:\n","      norm_type (str) -- the name of the normalization layer: batch | instance | none\n","  For BatchNorm, we use learnable affine parameters and track running statistics (mean/stddev).\n","  For InstanceNorm, we do not use learnable affine parameters. We do not track running statistics.\n","  \"\"\"\n","  if norm_type == 'batch':\n","    norm_layer = functools.partial(nn.BatchNorm2d, affine=True, track_running_stats=True)\n","  elif norm_type == 'instance':\n","    norm_layer = functools.partial(nn.InstanceNorm2d, affine=False, track_running_stats=False)\n","  elif norm_type == 'none':\n","    def norm_layer(x): return Identity()\n","  else:\n","    raise NotImplementedError('normalization layer [%s] is not found' % norm_type)\n","  return norm_layer\n","\n","class Conv2d(torch.nn.Module):\n","  '''\n","  2D convolution class\n","  Args:\n","    in_channels : int\n","      number of input channels\n","    out_channels : int\n","      number of output channels\n","    kernel_size : int\n","      size of kernel\n","    stride : int\n","      stride of convolution\n","    activation_func : func\n","      activation function after convolution\n","    norm_layer : functools.partial\n","      normalization layer\n","    use_bias : bool\n","      if set, then use bias\n","    padding_type : str\n","      the name of padding layer: reflect | replicate | zero\n","  '''\n","\n","  def __init__(\n","      self,\n","      in_channels,\n","      out_channels,\n","      kernel_size=3,\n","      stride=1,\n","      activation_func=torch.nn.LeakyReLU(negative_slope=0.10, inplace=True),\n","      norm_layer=nn.BatchNorm2d,\n","      use_bias=False,\n","      padding_type='reflect'):\n","    super(Conv2d, self).__init__()\n","    \n","    self.activation_func = activation_func\n","    conv_block = []\n","    p = 0\n","    if padding_type == 'reflect':\n","      conv_block += [nn.ReflectionPad2d(kernel_size // 2)]\n","    elif padding_type == 'replicate':\n","      conv_block += [nn.ReplicationPad2d(kernel_size // 2)]\n","    elif padding_type == 'zero':\n","      p = kernel_size // 2\n","    else:\n","      raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n","\n","    conv_block += [\n","        nn.Conv2d(\n","            in_channels, \n","            out_channels, \n","            stride=stride,\n","            kernel_size=kernel_size, \n","            padding=p, \n","            bias=use_bias), \n","        norm_layer(out_channels)]\n","\n","    self.conv = nn.Sequential(*conv_block)\n","\n","  def forward(self, x):\n","    conv = self.conv(x)\n","\n","    if self.activation_func is not None:\n","      return self.activation_func(conv)\n","    else:\n","      return conv\n","\n","class DeformableConv2d(nn.Module):\n","  '''\n","  2D deformable convolution class\n","  Args:\n","    in_channels : int\n","      number of input channels\n","    out_channels : int\n","      number of output channels\n","    kernel_size : int\n","      size of kernel\n","    stride : int\n","      stride of convolution\n","    padding : int\n","      padding\n","    use_bias : bool\n","      if set, then use bias\n","  '''\n","  def __init__(\n","      self,\n","      in_channels,\n","      out_channels,\n","      kernel_size=3,\n","      stride=1,\n","      padding=1,\n","      bias=False):\n","\n","    super(DeformableConv2d, self).__init__()\n","    \n","    self.stride = stride if type(stride) == tuple else (stride, stride)\n","    self.padding = padding\n","    \n","    self.offset_conv = nn.Conv2d(\n","        in_channels, \n","        2 * kernel_size * kernel_size,\n","        kernel_size=kernel_size, \n","        stride=stride,\n","        padding=self.padding, \n","        bias=True)\n","\n","    nn.init.constant_(self.offset_conv.weight, 0.)\n","    nn.init.constant_(self.offset_conv.bias, 0.)\n","    \n","    self.modulator_conv = nn.Conv2d(\n","        in_channels, \n","        1 * kernel_size * kernel_size,\n","        kernel_size=kernel_size, \n","        stride=stride,\n","        padding=self.padding, \n","        bias=True)\n","\n","    nn.init.constant_(self.modulator_conv.weight, 0.)\n","    nn.init.constant_(self.modulator_conv.bias, 0.)\n","    \n","    self.regular_conv = nn.Conv2d(\n","        in_channels=in_channels,\n","        out_channels=out_channels,\n","        kernel_size=kernel_size,\n","        stride=stride,\n","        padding=self.padding,\n","        bias=bias)\n","\n","  def forward(self, x):\n","    offset = self.offset_conv(x)\n","    modulator = 2. * torch.sigmoid(self.modulator_conv(x))\n","    \n","    x = torchvision.ops.deform_conv2d(\n","        input=x, \n","        offset=offset, \n","        weight=self.regular_conv.weight, \n","        bias=self.regular_conv.bias, \n","        padding=self.padding,\n","        mask=modulator,\n","        stride=self.stride)\n","    return x\n","\n","class UpConv2d(torch.nn.Module):\n","  '''\n","  Up-convolution (upsample + convolution) block class\n","  Args:\n","    in_channels : int\n","      number of input channels\n","    out_channels : int\n","      number of output channels\n","    kernel_size : int\n","      size of kernel (k x k)\n","    activation_func : func\n","      activation function after convolution\n","    norm_layer : functools.partial\n","      normalization layer\n","    use_bias : bool\n","      if set, then use bias\n","    padding_type : str\n","      the name of padding layer: reflect | replicate | zero\n","    interpolate_mode : str\n","      the mode for interpolation: bilinear | nearest\n","  '''\n","  def __init__(\n","      self,\n","      in_channels,\n","      out_channels,\n","      kernel_size=3,\n","      activation_func=torch.nn.LeakyReLU(negative_slope=0.10, inplace=True),\n","      norm_layer=nn.BatchNorm2d,\n","      use_bias=False,\n","      padding_type='reflect',\n","      interpolate_mode='bilinear'):\n","    \n","    super(UpConv2d, self).__init__()\n","    self.interpolate_mode = interpolate_mode\n","\n","    self.conv = Conv2d(\n","        in_channels,\n","        out_channels,\n","        kernel_size=kernel_size,\n","        stride=1,\n","        activation_func=activation_func,\n","        norm_layer=norm_layer,\n","        use_bias=use_bias,\n","        padding_type=padding_type)\n","\n","  def forward(self, x):\n","    n_height, n_width = x.shape[2:4]\n","    shape = (int(2 * n_height), int(2 * n_width))\n","    upsample = torch.nn.functional.interpolate(\n","        x, size=shape, mode=self.interpolate_mode, align_corners=True)\n","    conv = self.conv(upsample)\n","    return conv\n","\n","class DeformableResnetBlock(nn.Module):\n","  \"\"\"Define a Resnet block with deformable convolutions\"\"\"\n","\n","  def __init__(\n","      self, dim, padding_type, \n","      norm_layer, use_dropout, \n","      use_bias, activation_func):\n","    \"\"\"Initialize the deformable Resnet block\n","    A defromable resnet block is a conv block with skip connections\n","    \"\"\"\n","    super(DeformableResnetBlock, self).__init__()\n","    self.conv_block = self.build_conv_block(\n","        dim, padding_type, \n","        norm_layer, use_dropout, \n","        use_bias, activation_func)\n","\n","  def build_conv_block(\n","      self, dim, padding_type, \n","      norm_layer, use_dropout, \n","      use_bias, activation_func):\n","    \"\"\"Construct a convolutional block.\n","    Parameters:\n","        dim (int) -- the number of channels in the conv layer.\n","        padding_type (str) -- the name of padding layer: reflect | replicate | zero\n","        norm_layer -- normalization layer\n","        use_dropout (bool) -- if use dropout layers.\n","        use_bias (bool) -- if the conv layer uses bias or not\n","        activation_func (func) -- activation type\n","    Returns a conv block (with a conv layer, a normalization layer, and a non-linearity layer)\n","    \"\"\"\n","    conv_block = []\n","\n","    p = 0\n","    if padding_type == 'reflect':\n","      conv_block += [nn.ReflectionPad2d(1)]\n","    elif padding_type == 'replicate':\n","      conv_block += [nn.ReplicationPad2d(1)]\n","    elif padding_type == 'zero':\n","      p = 1\n","    else:\n","      raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n","\n","    conv_block += [\n","        DeformableConv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), \n","        norm_layer(dim), \n","        activation_func]\n","    if use_dropout:\n","      conv_block += [nn.Dropout(0.5)]\n","\n","    p = 0\n","    if padding_type == 'reflect':\n","      conv_block += [nn.ReflectionPad2d(1)]\n","    elif padding_type == 'replicate':\n","      conv_block += [nn.ReplicationPad2d(1)]\n","    elif padding_type == 'zero':\n","      p = 1\n","    else:\n","      raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n","    conv_block += [DeformableConv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim)]\n","\n","    return nn.Sequential(*conv_block)\n","\n","  def forward(self, x):\n","    \"\"\"Forward function (with skip connections)\"\"\"\n","    out = x + self.conv_block(x)    # add skip connections\n","    return out\n","\n","class DecoderBlock(torch.nn.Module):\n","  '''\n","  Decoder block with skip connections\n","  Args:\n","    in_channels : int\n","      number of input channels\n","    skip_channels : int\n","      number of skip connection channels\n","    out_channels : int\n","      number of output channels\n","    activation_func : func\n","      activation function after convolution\n","    norm_layer : functools.partial\n","      normalization layer\n","    use_bias : bool\n","      if set, then use bias\n","    padding_type : str\n","      the name of padding layer: reflect | replicate | zero\n","    upsample_mode : str\n","      the mode for interpolation: transpose | bilinear | nearest\n","  '''\n","\n","  def __init__(\n","      self,\n","      in_channels,\n","      skip_channels,\n","      out_channels,\n","      activation_func=torch.nn.LeakyReLU(negative_slope=0.10, inplace=True),\n","      norm_layer=nn.BatchNorm2d,\n","      use_bias=False,\n","      padding_type='reflect',\n","      upsample_mode='transpose'):\n","    super(DecoderBlock, self).__init__()\n","\n","    self.skip_channels = skip_channels\n","    self.upsample_mode = upsample_mode\n","    \n","    # Upsampling\n","    if upsample_mode == 'transpose':\n","      self.deconv = nn.Sequential(\n","          nn.ConvTranspose2d(\n","              in_channels, out_channels,\n","              kernel_size=3, stride=2,\n","              padding=1, output_padding=1,\n","              bias=use_bias),\n","          norm_layer(out_channels),\n","          activation_func)\n","    else:\n","      self.deconv = UpConv2d(\n","          in_channels, out_channels,\n","          use_bias=use_bias,\n","          activation_func=activation_func,\n","          norm_layer=norm_layer,\n","          padding_type=padding_type,\n","          interpolate_mode=upsample_mode)\n","\n","    concat_channels = skip_channels + out_channels\n","    \n","    self.conv = Conv2d(\n","        concat_channels,\n","        out_channels,\n","        kernel_size=3,\n","        stride=1,\n","        activation_func=activation_func,\n","        padding_type=padding_type,\n","        norm_layer=norm_layer,\n","        use_bias=use_bias)\n","\n","  def forward(self, x, skip=None):\n","    deconv = self.deconv(x)\n","\n","    if self.skip_channels > 0:\n","      concat = torch.cat([deconv, skip], dim=1)\n","    else:\n","      concat = deconv\n","\n","    return self.conv(concat)"],"metadata":{"id":"Wg-OoS5f4DyZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def init_weights(net, init_type='normal', init_gain=0.02):\n","  \"\"\"\n","  Initialize network weights.\n","  Parameters:\n","      net (network) -- network to be initialized\n","      init_type (str) -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n","      init_gain (float) -- scaling factor for normal, xavier and orthogonal.\n","  \"\"\"\n","  def init_func(m):  # define the initialization function\n","    classname = m.__class__.__name__\n","    if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n","      if init_type == 'normal':\n","        init.normal_(m.weight.data, 0.0, init_gain)\n","      elif init_type == 'xavier':\n","        init.xavier_normal_(m.weight.data, gain=init_gain)\n","      elif init_type == 'kaiming':\n","        init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n","      elif init_type == 'orthogonal':\n","        init.orthogonal_(m.weight.data, gain=init_gain)\n","      else:\n","        raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n","      if hasattr(m, 'bias') and m.bias is not None:\n","        init.constant_(m.bias.data, 0.0)\n","    elif classname.find('BatchNorm2d') != -1:  # BatchNorm Layer's weight is not a matrix; only normal distribution applies.\n","      init.normal_(m.weight.data, 1.0, init_gain)\n","      init.constant_(m.bias.data, 0.0)\n","\n","  print('initialize network with %s' % init_type)\n","  net.apply(init_func)  # apply the initialization function <init_func>\n","\n","def init_net(net, init_type='normal', init_gain=0.02, gpu_ids=[]):\n","  \"\"\"Initialize a network: 1. register CPU/GPU device (with multi-GPU support); 2. initialize the network weights\n","  Parameters:\n","          net (network) -- the network to be initialized\n","          init_type (str) -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n","          gain (float) -- scaling factor for normal, xavier and orthogonal.\n","          gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n","  Return an initialized network.\n","  \"\"\"\n","  if len(gpu_ids) > 0:\n","    assert(torch.cuda.is_available())\n","    net.to(gpu_ids[0])\n","    net = torch.nn.DataParallel(net, gpu_ids)    # multi-GPUs\n","  init_weights(net, init_type, init_gain=init_gain)\n","  \n","  # Zero for deform convs\n","  key_name_list = ['offset', 'modulator']\n","  for cur_name, parameters in net.named_parameters():\n","    if any(key_name in cur_name for key_name in key_name_list):\n","      nn.init.constant_(parameters, 0.)\n","  return net\n","\n","class ResNetModified(nn.Module):\n","  \"\"\"\n","  Resnet-based generator that consists of deformable Resnet blocks.\n","  \"\"\"\n","\n","  def __init__(\n","      self, \n","      input_nc, \n","      output_nc, \n","      ngf=64, \n","      norm_layer=nn.BatchNorm2d, \n","      activation_func=torch.nn.LeakyReLU(negative_slope=0.10, inplace=True),\n","      use_dropout=False, \n","      n_blocks=6, \n","      padding_type='reflect',\n","      upsample_mode='bilinear'):\n","    \"\"\"Construct a Resnet-based generator\n","    Parameters:\n","      input_nc (int) -- the number of channels in input images\n","      output_nc (int) -- the number of channels in output images\n","      ngf (int) -- the number of filters in the last conv layer\n","      norm_layer -- normalization layer\n","      use_dropout (bool) -- if use dropout layers\n","      n_blocks (int) -- the number of ResNet blocks\n","      padding_type (str) -- the name of padding layer in conv layers: reflect | replicate | zero\n","      upsample_mode (str) -- mode for upsampling: transpose | bilinear\n","    \"\"\"\n","    assert(n_blocks >= 0)\n","    super(ResNetModified, self).__init__()\n","    if type(norm_layer) == functools.partial:\n","      use_bias = norm_layer.func == nn.InstanceNorm2d\n","    else:\n","      use_bias = norm_layer == nn.InstanceNorm2d\n","\n","    # Initial Convolution\n","    self.initial_conv = nn.Sequential(\n","        Conv2d(\n","            in_channels=input_nc,\n","            out_channels=ngf,\n","            kernel_size=7,\n","            padding_type=padding_type,\n","            norm_layer=norm_layer,\n","            activation_func=activation_func,\n","            use_bias=use_bias),\n","        Conv2d(\n","            in_channels=ngf,\n","            out_channels=ngf,\n","            kernel_size=3,\n","            padding_type=padding_type,\n","            norm_layer=norm_layer,\n","            activation_func=activation_func,\n","            use_bias=use_bias))\n","\n","    # Downsample Blocks\n","    n_downsampling = 2\n","    mult = 2 ** 0\n","    self.downsample_1 = Conv2d(\n","        in_channels=ngf * mult,\n","        out_channels=ngf * mult * 2,\n","        kernel_size=3,\n","        stride=2,\n","        padding_type=padding_type,\n","        norm_layer=norm_layer,\n","        activation_func=activation_func,\n","        use_bias=use_bias)\n","    \n","    mult = 2 ** 1\n","    self.downsample_2 = Conv2d(\n","        in_channels=ngf * mult,\n","        out_channels=ngf * mult * 2,\n","        kernel_size=3,\n","        stride=2,\n","        padding_type=padding_type,\n","        norm_layer=norm_layer,\n","        activation_func=activation_func,\n","        use_bias=use_bias)\n","\n","    # Residual Blocks\n","    residual_blocks = []\n","    mult = 2 ** n_downsampling\n","    for i in range(n_blocks): # add ResNet blocks\n","      residual_blocks += [\n","          DeformableResnetBlock(\n","              ngf * mult, \n","              padding_type=padding_type, \n","              norm_layer=norm_layer, \n","              use_dropout=use_dropout, \n","              use_bias=use_bias, activation_func=activation_func)]\n","    \n","    self.residual_blocks = nn.Sequential(*residual_blocks)\n","\n","    # Upsampling\n","    mult = 2 ** (n_downsampling - 0)\n","    self.upsample_2 = DecoderBlock(\n","        ngf * mult, \n","        int(ngf * mult / 2),\n","        int(ngf * mult / 2),\n","        use_bias=use_bias,\n","        activation_func=activation_func,\n","        norm_layer=norm_layer,\n","        padding_type=padding_type,\n","        upsample_mode=upsample_mode)\n","    \n","    mult = 2 ** (n_downsampling - 1)\n","    self.upsample_1 = DecoderBlock(\n","        ngf * mult, \n","        int(ngf * mult / 2),\n","        int(ngf * mult / 2),\n","        use_bias=use_bias,\n","        activation_func=activation_func,\n","        norm_layer=norm_layer,\n","        padding_type=padding_type,\n","        upsample_mode=upsample_mode)\n","    \n","    # Output Convolution\n","    self.output_conv_naive = nn.Sequential(\n","        nn.ReflectionPad2d(1),\n","        nn.Conv2d(ngf, output_nc, kernel_size=3, padding=0),\n","        nn.Tanh())\n","\n","    # # Projection for rain robust loss\n","    # self.feature_projection = nn.Sequential(\n","    #     nn.AdaptiveAvgPool2d((2, 2)),\n","    #     nn.Flatten(start_dim=1, end_dim=-1))\n","\n","  def forward(self, input):\n","    \"\"\"Standard forward\"\"\"\n","\n","    # Downsample\n","    initial_conv_out  = self.initial_conv(input)\n","    downsample_1_out = self.downsample_1(initial_conv_out)\n","    downsample_2_out = self.downsample_2(downsample_1_out)\n","\n","    # Residual\n","    residual_blocks_out = self.residual_blocks(downsample_2_out)\n","\n","    # Upsample\n","    upsample_2_out = self.upsample_2(residual_blocks_out, downsample_1_out)\n","    upsample_1_out = self.upsample_1(upsample_2_out, initial_conv_out)\n","    final_out = self.output_conv_naive(upsample_1_out)\n","\n","    # Features\n","    # features = self.feature_projection(residual_blocks_out)\n","\n","    # Return multiple final conv results\n","    return final_out, # features\n","\n","class GTRainModel(nn.Module):\n","  def __init__(\n","      self, \n","      ngf=64,\n","      n_blocks=9,\n","      norm_layer_type='batch',\n","      activation_func=torch.nn.LeakyReLU(negative_slope=0.10, inplace=True),\n","      upsample_mode='bilinear',\n","      init_type='kaiming'):\n","    \"\"\"\n","    GT-Rain Model\n","    Parameters:\n","      ngf (int) -- the number of conv filters\n","      n_blocks (int) -- the number of deformable ResNet blocks\n","      norm_layer_type (str) -- 'batch', 'instance'\n","      activation_func (func) -- activation functions\n","      upsample_mode (str) -- 'transpose', 'bilinear'\n","      init_type (str) -- None, 'normal', 'xavier', 'kaiming', 'orthogonal'\n","    \"\"\"\n","    super(GTRainModel, self).__init__()\n","    self.resnet = ResNetModified(\n","      input_nc=3, output_nc=3, ngf=ngf, \n","      norm_layer=get_norm_layer(norm_layer_type),\n","      activation_func=activation_func,\n","      use_dropout=False, n_blocks=n_blocks, \n","      padding_type='reflect',\n","      upsample_mode=upsample_mode)\n","\n","    # Initialization\n","    if init_type:\n","      init_net(self.resnet, init_type=init_type)\n","\n","  def forward(self, x):\n","    out_img = self.resnet(x)\n","    return out_img "],"metadata":{"id":"LibNgHWm4MIr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jht1wzqDDjJf"},"source":["# Parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NnJC-9nxpRlt"},"outputs":[],"source":["params = {\n","  'load_checkpoint': './checkpoints/weights_dir', # Dir to load model weights\n","  'input_path': '/path/to/input',\n","  'gt_path': '/path/to/gt',\n","  'save_path': './outputs/',\n","  'init_type': 'normal', # Initialization type \n","  'norm_layer_type': 'batch', # Normalization type\n","  'activation_func': torch.nn.LeakyReLU(negative_slope=0.10, inplace=True), # Activation function\n","  'upsample_mode': 'bilinear', # Mode for upsampling\n","  'ngf': 64,\n","  'n_blocks': 9}\n","\n","os.makedirs(params['save_path'], exist_ok=True)"]},{"cell_type":"markdown","source":["# Load Model"],"metadata":{"id":"m9jjxGsODD8F"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"za8W7tG_H3zZ"},"outputs":[],"source":["# Make the model\n","model = GTRainModel(\n","  ngf=params['ngf'],\n","  n_blocks=params['n_blocks'],\n","  norm_layer_type=params['norm_layer_type'],\n","  activation_func=params['activation_func'],\n","  upsample_mode=params['upsample_mode'],\n","  init_type=params['init_type'])\n","\n","print(model)\n","model.cuda()"]},{"cell_type":"code","source":["# Load model weights\n","print('Loading weights:', params['load_checkpoint'])\n","checkpoint = torch.load(params['load_checkpoint']) #, map_location=torch.device('cpu')\n","model.load_state_dict(checkpoint['state_dict'], strict=True) #strict=True\n","model.eval()"],"metadata":{"id":"t6IrOcuN8mrN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Testing Code"],"metadata":{"id":"IIP37_kzDHt2"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"MjiVjuLRpqI9"},"outputs":[],"source":["# Section for running with generic test sets\n","if params['gt_path']:\n","  total_PSNR_input = 0\n","  total_SSIM_input = 0\n","  total_PSNR_output = 0\n","  total_SSIM_output = 0\n","  clean_img_paths = natsorted(glob(params['gt_path']))\n","\n","rainy_img_paths = natsorted(glob(params['input_path']))\n","num_paths = len(rainy_img_paths)\n","\n","for i in tqdm(range(num_paths)):\n","  filename = rainy_img_paths[i].split('/')[-1][:-4]\n","  img = Image.open(rainy_img_paths[i])\n","  img = np.array(img, dtype=np.float32)\n","  img *= 1/255\n","  height, width = img.shape[:2]\n","\n","  img = img[:height-height%4,:width-width%4,:]\n","  input = torch.from_numpy(img).permute((2, 0, 1)) * 2 - 1\n","  input = torch.unsqueeze(input, 0).cuda()\n","  output = (model(input)[0]* 0.5 + 0.5).squeeze().permute((1, 2, 0))\n","  output = output.detach().cpu().numpy()\n","\n","  if params['gt_path']:\n","    gt_img = Image.open(clean_img_paths[i])\n","    gt_img = np.array(gt_img, dtype=np.float32)\n","    gt_img *= 1/255\n","    gt_img = gt_img[:height-height%4,:width-width%4,:]  \n","    total_PSNR_input += psnr(gt_img, img)\n","    total_SSIM_input += ssim(gt_img, img, multichannel=True)\n","    total_PSNR_output += psnr(gt_img, output)\n","    total_SSIM_output += ssim(gt_img, output, multichannel=True)\n","\n","  # USE THIS BLOCK TO SAVE\n","  im = Image.fromarray((output*255).astype(np.uint8))\n","  im.save(f\"{params['save_path']}/{filename}.png\")\n","\n","if params['gt_path']:\n","  print(f\"PSNR Input: {total_PSNR_input/num_paths}\")\n","  print(f\"SSIM Input: {total_SSIM_input/num_paths}\")\n","  print(f\"PSNR Output: {total_PSNR_output/num_paths}\")\n","  print(f\"SSIM Output: {total_SSIM_output/num_paths}\")"]},{"cell_type":"code","source":["# Section for running on GT-RAIN test set\n","total_PSNR_input = 0\n","total_SSIM_input = 0\n","total_PSNR_output = 0\n","total_SSIM_output = 0\n","\n","rain_acc_total_PSNR_input = 0\n","rain_acc_total_SSIM_input = 0\n","rain_acc_total_PSNR_output = 0\n","rain_acc_total_SSIM_output = 0\n","rain_acc_num_scenes = 0\n","\n","dense_streak_total_PSNR_input = 0\n","dense_streak_total_SSIM_input = 0\n","dense_streak_total_PSNR_output = 0\n","dense_streak_total_SSIM_output = 0\n","dense_streak_num_scenes = 0\n","\n","scene_paths = natsorted(glob(f\"{params['input_path']}/*\")\n","\n","for scene_path in tqdm(scene_paths):\n","  scene_name = scene_path.split('/')[-1]\n","  clean_img_path = glob(scene_path + '/*C-000.png')[0]\n","  rainy_img_paths = natsorted(glob(scene_path + '/*R-*.png'))\n","  scene_PSNR_input = 0\n","  scene_SSIM_input = 0\n","  scene_PSNR_output = 0\n","  scene_SSIM_output = 0\n","  \n","  for i in tqdm(range(len(rainy_img_paths))):\n","    filename = rainy_img_paths[i].split('/')[-1][:-4]\n","    img = Image.open(rainy_img_paths[i])\n","    gt_img = Image.open(clean_img_path)\n","    img = np.array(img, dtype=np.float32)\n","    img *= 1/255\n","    gt_img = np.array(gt_img, dtype=np.float32)\n","    gt_img *= 1/255\n","    height, width = img.shape[:2]\n","\n","    img = img[:height-height%4,:width-width%4,:]\n","    \n","    gt_img = gt_img[:height-height%4,:width-width%4,:]\n","    \n","    input = torch.from_numpy(img).permute((2, 0, 1)) * 2 - 1\n","    input = torch.unsqueeze(input, 0).cuda()\n","    output = (model(input)[0]* 0.5 + 0.5).squeeze().permute((1, 2, 0))\n","    output = output.detach().cpu().numpy()\n","\n","    # USE THIS BLOCK TO SAVE\n","    im = Image.fromarray((output*255).astype(np.uint8))\n","    im.save(f\"{params['save_path']}/{scene_name}/{filename}.png\")\n","\n","    scene_PSNR_input += psnr(gt_img, img)\n","    scene_SSIM_input += ssim(gt_img, img, multichannel=True)\n","    scene_PSNR_output += psnr(gt_img, output)\n","    scene_SSIM_output += ssim(gt_img, output, multichannel=True)\n","  print(f\"Scene: {scene_name}\")\n","  print(f\"Scene PSNR Input: {scene_PSNR_input/len(rainy_img_paths)}\")\n","  print(f\"Scene SSIM Input: {scene_SSIM_input/len(rainy_img_paths)}\")\n","  print(f\"Scene PSNR Output: {scene_PSNR_output/len(rainy_img_paths)}\")\n","  print(f\"Scene SSIM Output: {scene_SSIM_output/len(rainy_img_paths)}\")\n","\n","  total_PSNR_input += scene_PSNR_input/len(rainy_img_paths)\n","  total_SSIM_input += scene_SSIM_input/len(rainy_img_paths)\n","  total_PSNR_output += scene_PSNR_output/len(rainy_img_paths)\n","  total_SSIM_output += scene_SSIM_output/len(rainy_img_paths)\n","\n","  if scene_name in [\"Oinari_0-0\", \"M1135_0-0\", \"Table_Rock_0-0\"]:\n","    rain_acc_total_PSNR_input += scene_PSNR_input/len(rainy_img_paths) \n","    rain_acc_total_SSIM_input += scene_SSIM_input/len(rainy_img_paths)\n","    rain_acc_total_PSNR_output += scene_PSNR_output/len(rainy_img_paths)\n","    rain_acc_total_SSIM_output += scene_SSIM_output/len(rainy_img_paths)\n","    rain_acc_num_scenes+=1\n","  else:\n","    dense_streak_total_PSNR_input+= scene_PSNR_input/len(rainy_img_paths)\n","    dense_streak_total_SSIM_input += scene_SSIM_input/len(rainy_img_paths)\n","    dense_streak_total_PSNR_output += scene_PSNR_output/len(rainy_img_paths)\n","    dense_streak_total_SSIM_output += scene_SSIM_output/len(rainy_img_paths)\n","    dense_streak_num_scenes+=1\n","num_scenes = len(scene_paths)\n","print(f\"Total PSNR Input: {total_PSNR_input/(num_scenes)}\")\n","print(f\"Total SSIM Input: {total_SSIM_input/num_scenes}\")\n","print(f\"Total PSNR Output: {total_PSNR_output/num_scenes}\")\n","print(f\"Total SSIM Output: {total_SSIM_output/num_scenes}\")\n","\n","print(f\"rain accumulation Total PSNR Input: {rain_acc_total_PSNR_input/(rain_acc_num_scenes)}\")\n","print(f\"rain accumulation Total SSIM Input: {rain_acc_total_SSIM_input/rain_acc_num_scenes}\")\n","print(f\"rain accumulation Total PSNR Output: {rain_acc_total_PSNR_output/rain_acc_num_scenes}\")\n","print(f\"rain accumulation Total SSIM Output: {rain_acc_total_SSIM_output/rain_acc_num_scenes}\")\n","\n","print(f\"dense streak Total PSNR Input: {dense_streak_total_PSNR_input/(dense_streak_num_scenes)}\")\n","print(f\"dense streak Total SSIM Input: {dense_streak_total_SSIM_input/dense_streak_num_scenes}\")\n","print(f\"dense streak Total PSNR Output: {dense_streak_total_PSNR_output/dense_streak_num_scenes}\")\n","print(f\"dense streak Total SSIM Output: {dense_streak_total_SSIM_output/dense_streak_num_scenes}\")"],"metadata":{"id":"bol1boaGy7L1"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}